% DON'T CHANGE THIS LINE
\addcontentsline{toc}{section}{\ifcase\doclanguage\or Resum \or Resumen \else Summary\fi}

%%%% PLEASE REPLACE TEXTS WITH YOUR OWN CONTENT %%%%

%%% RESUM EN CATALÀ
\begin{center}
  \huge\bfseries\raggedright Resum~\hrulefill
\end{center}
  %Cada exemplar del Treball de Fi de Grau (TFG) ha de contenir un Resum, que és un breu extracte del TFG. En termes d'estil, el Resum hauria de ser una versió reduïda del projecte: una introducció concisa, un compendi dels resultats i les principals conclusions o arguments presentats en el projecte. El Resum no ha de superar les 150 paraules i cal que estigui traduït al català, castellà i anglès.
  
  Aquest projecte té com a objectiu millorar l'eficiència i la usabilitat de grans models d'IA, específicament els models d'aprenentatge profund utilitzats en Visió per Computador quan es despleguen en dispositius perimetrals amb recursos limitats. El nostre objectiu és reduir les demandes computacionals d'aquests models sense sacrificar el rendiment desenvolupant una cadena modular que integra les tècniques de destil·lació de coneixement, l'ajustament de paràmetres amb LoRA i quantificació. El projecte quantifica els compromisos entre el rendiment i l'eficiència del model en cada etapa de la cadena. Això s'aconsegueix integrant tres metodologies bàsiques per reduir un gran model d'IA (ResNet-18) a una versió compacta i eficient (MobileNetV2).

%%% RESUMEN EN CASTELLANO
\begin{center}
  \huge\bfseries\raggedleft\vspace*{.5\baselineskip} \hrulefill ~Resumen
\end{center}
  Este proyecto busca mejorar la eficiencia y la usabilidad de grandes modelos de IA, en concreto los modelos de aprendizaje profundo utilizados en Visión Artificial al implementarse en dispositivos perimetrales con recursos limitados. Buscamos reducir la demanda computacional de estos modelos sin sacrificar el rendimiento mediante el desarrollo de una canalización modular que integra técnicas de destilación de conocimiento, ajuste de parámetros con LoRA y cuantificación. El proyecto cuantifica el intercambio entre el rendimiento y la eficiencia del modelo en cada etapa de la canalización. Esto se logra integrando tres metodologías principales para reducir un gran modelo de IA (ResNet-18) a una versión compacta y eficiente (MobileNetV2).

%%% ENGLISH SUMMARY
\begin{center}
  \huge\bfseries\raggedright\vspace*{.5\baselineskip} Summary~\hrulefill
\end{center}
  This project aims to enhance the efficiency and usability of large AI models, specifically deep learning models used in Computer Vision when deployed on edge devices with limited resources. We aim to reduce the computational demands of these models without sacrificing performance by developing a modular pipeline that integrates knowledge distillation, LoRA fine-tuning, and quantization techniques. The project quantifies the trade-offs between model performance and efficiency at each stage of the pipeline. This is achieved by integrating three core methodologies to shrink a large AI model (ResNet-18) into a compact, efficient version (MobileNetV2).
